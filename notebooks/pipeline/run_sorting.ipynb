{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T20:00:58.806552Z",
     "iopub.status.busy": "2020-12-31T20:00:58.806111Z",
     "iopub.status.idle": "2020-12-31T20:00:58.823039Z",
     "shell.execute_reply": "2020-12-31T20:00:58.821897Z",
     "shell.execute_reply.started": "2020-12-31T20:00:58.806495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running time\n",
    "\n",
    "/Volumes/neuropixel:\n",
    "    - Alessandro rem-stim2 (56GB): 1h45 (including binfile copying with 20 jobs <20min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T20:00:59.955640Z",
     "iopub.status.busy": "2020-12-31T20:00:59.955323Z",
     "iopub.status.idle": "2020-12-31T20:01:00.496425Z",
     "shell.execute_reply": "2020-12-31T20:01:00.495867Z",
     "shell.execute_reply.started": "2020-12-31T20:00:59.955600Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.toolkit as st\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecephys_analyses.data import channel_groups, paths, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ironclust', 'kilosort', 'kilosort2_5', 'kilosort3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USER\n",
    "\n",
    "sorting_conditions = [\n",
    "    'ks2_5_catgt_df'\n",
    "#     'ks3_catgt_df'\n",
    "]\n",
    "\n",
    "# Subject, condition, catgt data\n",
    "data_conditions = [\n",
    "    ('Allan', 'g2-1', True),\n",
    "    ('Allan', 'g2-0', True),\n",
    "#     ('Alessandro', 'rem-stim', True),\n",
    "#     ('Alessandro', 'rem-stim2', True),\n",
    "#     ('Alessandro', 'sleep-stim', True),\n",
    "#     ('Alessandro', 'West', True),\n",
    "    \n",
    "]\n",
    "\n",
    "n_jobs = 1  # Don't parallelize (possibly messed up tmp directories?)\n",
    "\n",
    "## end USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sorting(subject, condition, sorting_condition,\n",
    "                catgt_data=True, bad_channels=None, rerun_existing=True):\n",
    "    \n",
    "    # Sorter parameters\n",
    "    sorter, params = parameters.get_analysis_params(\n",
    "        'sorting',\n",
    "        sorting_condition\n",
    "    )\n",
    "    \n",
    "    # Recording\n",
    "    rec = prepare_data(\n",
    "        subject, \n",
    "        condition,\n",
    "        catgt_data=catgt_data,\n",
    "        bad_channels=bad_channels\n",
    "    )\n",
    "    \n",
    "    # Path \n",
    "    output_dir = paths.get_sglx_style_datapaths(\n",
    "        subject,\n",
    "        condition,\n",
    "        'dummy',\n",
    "        catgt_data=catgt_data\n",
    "    )[0].parent/sorting_condition\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    print(f\"Saving sorting output at {output_dir}\")\n",
    "    \n",
    "    \n",
    "    # rerun existing\n",
    "    if (output_dir/'spike_times.npy').exists() and not rerun_existing:\n",
    "        print(f'Passing: output directory is done: {output_dir}\\n\\n')\n",
    "        return\n",
    "\n",
    "    print('running')\n",
    "    start = datetime.now()\n",
    "    ss.run_sorter(\n",
    "        sorter,\n",
    "        rec,\n",
    "        output_folder=output_dir,\n",
    "        verbose=True,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    end = datetime.now()\n",
    "    print(f\"{end.strftime('%H:%M:%S')}: Finished {subject}, {condition}, {sorting_condition}.\")\n",
    "    print(f\"Run time = {str(end - start)}\\n\")\n",
    "\n",
    "\n",
    "    return 1\n",
    "\n",
    "def prepare_data(subject, condition, catgt_data=True, bad_channels=None):\n",
    "\n",
    "    binpaths = paths.get_sglx_style_datapaths(\n",
    "        subject,\n",
    "        condition,\n",
    "        'ap.bin',\n",
    "        catgt_data=catgt_data\n",
    "    )\n",
    "    \n",
    "    rec_extractors = [\n",
    "        se.SpikeGLXRecordingExtractor(binpath)\n",
    "        for binpath in binpaths\n",
    "    ]\n",
    "    if len(rec_extractors) == 1:\n",
    "        recording = rec_extractors[0]\n",
    "    else:    \n",
    "        recording = se.MultiRecordingTimeExtractor(extractors)\n",
    "    \n",
    "    assign_locations(recording, binpaths[0])\n",
    "\n",
    "    if bad_channels is not None:\n",
    "        recording = st.preprocessing.remove_bad_channels(\n",
    "            recording, bad_channel_ids=bad_channels\n",
    "        )\n",
    "        \n",
    "    return recording\n",
    "\n",
    "def assign_locations(recording, binpath, plot=False):\n",
    "    print(binpath)\n",
    "    from ecephys.sglx_utils import get_xy_coords\n",
    "    idx, x, y = get_xy_coords(binpath)\n",
    "    recording.set_channel_locations(\n",
    "        [(x[i], y[i]) for i in range(len(idx))],\n",
    "        channel_ids=idx,\n",
    "    )\n",
    "    if plot:\n",
    "        from ecephys.plot import plot_channel_coords\n",
    "        plot_channel_coords(range(len(x)), x, y)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allan g2-1 True ks2_5_catgt_df\n",
      "/Volumes/neuropixel/Data/tom/catgt/CNPIX8-Allan/3-5-2021/catgt_3-5-2021_g2/3-5-2021_g2_imec1/3-5-2021_g2_tcat.imec1.ap.bin\n",
      "0\n",
      "Saving sorting output at /Volumes/neuropixel/Data/tom/catgt/CNPIX8-Allan/3-5-2021/catgt_3-5-2021_g2/3-5-2021_g2_imec1/ks2_5_catgt_df\n",
      "running\n",
      "RUNNING SHELL SCRIPT: sh /Volumes/neuropixel/Data/tom/catgt/CNPIX8-Allan/3-5-2021/catgt_3-5-2021_g2/3-5-2021_g2_imec1/ks2_5_catgt_df/run_kilosort2_5.sh\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2019 The MathWorks, Inc.\n",
      "\n",
      "                  R2019b (9.7.0.1190202) 64-bit (glnxa64)\n",
      "\n",
      "                              August 21, 2019\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2019 The MathWorks, Inc.\n",
      "\n",
      "                  R2019b (9.7.0.1190202) 64-bit (glnxa64)\n",
      "\n",
      "                              August 21, 2019\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Sourcing neuropix startup file at `/Volumes/scratch/neuropixels/matlab/startup.m`\n",
      "\n",
      "Sourcing neuropix startup file at `/Volumes/scratch/neuropixels/matlab/startup.m`\n",
      "\n",
      "Time   6s. Computing whitening matrix.. \n",
      "\n",
      "Time   6s. Computing whitening matrix.. \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Time  84s. Loading raw data and applying filters... \n",
      "\n",
      "Time  84s. Loading raw data and applying filters... \n",
      "\n",
      "Time 1721s. Finished preprocessing 498 batches. \n",
      "\n",
      "Time 1721s. Finished preprocessing 498 batches. \n",
      "\n",
      "pitch is 20 um\n",
      "\n",
      "pitch is 20 um\n",
      "\n",
      "4.78 sec, 1 batches, 9346 spikes \n",
      "\n",
      "4.78 sec, 1 batches, 9346 spikes \n",
      "\n",
      "488.12 sec, 101 batches, 976806 spikes \n",
      "\n",
      "488.12 sec, 101 batches, 976806 spikes \n",
      "\n",
      "672.27 sec, 201 batches, 1948333 spikes \n",
      "\n",
      "672.27 sec, 201 batches, 1948333 spikes \n",
      "\n",
      "884.44 sec, 301 batches, 2907568 spikes \n",
      "\n",
      "884.44 sec, 301 batches, 2907568 spikes \n",
      "\n",
      "1080.98 sec, 401 batches, 3885162 spikes \n",
      "\n",
      "1080.98 sec, 401 batches, 3885162 spikes \n",
      "\n",
      "1312.99 sec, 498 batches, 4818791 spikes \n",
      "\n",
      "1312.99 sec, 498 batches, 4818791 spikes \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-76dd93ab6bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mcatgt_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatgt_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbad_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mrerun_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         )\n\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-306c49631ce4>\u001b[0m in \u001b[0;36mrun_sorting\u001b[0;34m(subject, condition, sorting_condition, catgt_data, bad_channels, rerun_existing)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#     try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/scratch/neuropixels/packages/spikesorters/spikesorters/sorterlist.py\u001b[0m in \u001b[0;36mrun_sorter\u001b[0;34m(sorter_name_or_class, recording, output_folder, delete_output_folder, grouping_property, parallel, verbose, raise_error, n_jobs, joblib_backend, **params)\u001b[0m\n\u001b[1;32m     91\u001b[0m                          verbose=verbose, delete_output_folder=delete_output_folder)\n\u001b[1;32m     92\u001b[0m     \u001b[0msorter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0msorter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoblib_backend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoblib_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0msortingextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/scratch/neuropixels/packages/spikesorters/spikesorters/basesorter.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, raise_error, parallel, n_jobs, joblib_backend)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecording\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecording_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecording\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_folders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 Parallel(n_jobs=n_jobs, backend=joblib_backend)(\n",
      "\u001b[0;32m/Volumes/scratch/neuropixels/packages/spikesorters/spikesorters/kilosort2_5/kilosort2_5.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, recording, output_folder)\u001b[0m\n\u001b[1;32m    225\u001b[0m         shell_script = ShellScript(shell_cmd, script_path=output_folder / f'run_{self.sorter_name}',\n\u001b[1;32m    226\u001b[0m                                    log_path=output_folder / f'{self.sorter_name}.log', verbose=self.verbose)\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mshell_script\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshell_script\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/scratch/neuropixels/packages/spikesorters/spikesorters/utils/shellscript.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                          universal_newlines=True)\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_log_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscript_log_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mscript_log_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Print onto console depending on the verbose property passed on from the sorter class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if n_jobs == 1:\n",
    "    for (\n",
    "        (subject, condition, catgt_data),\n",
    "        sorting_condition\n",
    "    ) in itertools.product(data_conditions, sorting_conditions):\n",
    "        print(subject, condition, catgt_data, sorting_condition)\n",
    "        run_sorting(\n",
    "            subject,\n",
    "            condition,\n",
    "            sorting_condition,\n",
    "            catgt_data=catgt_data,\n",
    "            bad_channels=None,\n",
    "            rerun_existing=False\n",
    "        )\n",
    "else:\n",
    "    parallel = Parallel(\n",
    "        n_jobs=n_jobs,\n",
    "        backend='multiprocessing',\n",
    "    )(\n",
    "        delayed(run_sorting)(\n",
    "            subject,\n",
    "            condition,\n",
    "            sorting_condition,\n",
    "            catgt_data=catgt_data,\n",
    "            bad_channels=None,\n",
    "            rerun_existing=False\n",
    "        ) for ((subject, condition, catgt_data), sorting_condition)\n",
    "        in itertools.product(data_conditions, sorting_conditions)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
