{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time to concatenate 24 hours of LFP (12x 2hr files) = 30 minutes. \n",
    "- Size of 24 hours of LFP = ~160 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "from ecephys.sglx_utils.cat_gt import get_catGT_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_specs(subject, condition_group, rerun_existing=True):\n",
    "    \"\"\"If anyone reads this, sorry\"\"\"\n",
    "    from ecephys_analyses.data import paths\n",
    "    from ecephys_analyses.data.channel_groups import full_names\n",
    "    from ecephys.data.paths import parse_sglx_stem\n",
    "    conditions = paths.get_conditions(subject, condition_group)\n",
    "    datapath_dict = paths.load_datapath_yaml()\n",
    "    all_run_specs = []\n",
    "    for cond in conditions:\n",
    "        if not rerun_existing:\n",
    "            output_ap_meta = paths.get_sglx_style_datapaths(\n",
    "                subject, cond, 'ap.meta', catgt_data=True\n",
    "            )\n",
    "            if not len(output_ap_meta) == 1:\n",
    "                raise ValueError(f\"Multiple output meta files for {subject} {cond}.\"\n",
    "                                 f\"Only run catgt on non-combined conditions\")\n",
    "            if output_ap_meta[0].exists():\n",
    "                print(f\"Rerun=False: pass {subject} {cond}\", end=\"\")\n",
    "                print(f\"(found ap.meta at {output_ap_meta[0]}\")\n",
    "                continue\n",
    "        cond_spec = datapath_dict[subject][cond]\n",
    "        # Name\n",
    "        full_name = full_names[subject]\n",
    "        # exp\n",
    "        assert len(list(cond_spec.keys())) == 1\n",
    "        exp = list(cond_spec.keys())[0]\n",
    "        # run\n",
    "        stems = cond_spec[exp]\n",
    "        runs, gates, trigs, probes = zip(*[\n",
    "            parse_sglx_stem(stem) for stem in stems \n",
    "        ])\n",
    "        assert len(set(runs)) == 1  #TODO\n",
    "        assert len(set(probes)) == 1  #TODO\n",
    "        assert len(set(gates)) == 1  #TODO\n",
    "        sorted_trigs = sorted([int(t.split('t')[1]) for t in trigs])\n",
    "        trg_str = ','.join([str(t) for t in sorted_trigs])  # \"0,1,2,8\" or \"0\"\n",
    "        run, gate, trig, probe = parse_sglx_stem(stems[0])\n",
    "        all_run_specs.append(\n",
    "            tuple([subject, exp, run, {\n",
    "                'g': gate.split('g')[1],\n",
    "                'prb': probe.split('imec')[1],\n",
    "                't': trg_str,\n",
    "            }])\n",
    "        )\n",
    "    print(\"...\")\n",
    "    return all_run_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "# USER\n",
    "\n",
    "analysis_id = 'tom/catgt'\n",
    "\n",
    "catgt_base_cfg = {\n",
    "    'aphipass': 300,\n",
    "    'aplopass': 9000,\n",
    "    'gbldmx': True,\n",
    "    'gfix': '0.40,0.10,0.02',\n",
    "}  # Applied to all\n",
    "\n",
    "sync_channel = 384  # Applied to all\n",
    "\n",
    "###\n",
    "####\n",
    "######## Manual\n",
    "# Subject, experiment, run, catgt_cfg\n",
    "# catGT_cfg must contains the following keys: run, t, g, prb, \n",
    "# all_run_specs = [\n",
    "#     ('CNPIX3-Valentino', '2-19-2020', '2-19-2020',    {'g': '1', 'prb': '0', 't': '4,4',}), \n",
    "# ]\n",
    "########## Auto generation of bins to process\n",
    "\n",
    "# [(<subject>, <condition_group>), ]\n",
    "condition_groups = [\n",
    "    ('Doppio', 'SD_catgt'),\n",
    "    ('Allan', 'SD_catgt'),\n",
    "    ('Luigi', 'SD_catgt'),\n",
    "]\n",
    "\n",
    "rerun_existing=False  # Pass if output meta file exists\n",
    "\n",
    "all_run_specs = []\n",
    "for subject, condition_group in condition_groups:\n",
    "    all_run_specs += get_run_specs(subject, condition_group, rerun_existing=rerun_existing)\n",
    "print(f\"N runs (rerun_existing={rerun_existing}) = {len(all_run_specs)}\")\n",
    "print(f\"run specs (first 5). ```subject, experiment, run, catgt_cfg``` Looks good?: {all_run_specs[0:5]}\")\n",
    "\n",
    "####\n",
    "####\n",
    "####\n",
    "\n",
    "\n",
    "ap = True\n",
    "lf = False\n",
    "\n",
    "n_jobs = 1\n",
    "\n",
    "dry_run = True\n",
    "\n",
    "# END USER\n",
    "# ----------\n",
    "\n",
    "assert lf == False or rerun_existing  # Rerun logic only checks ap.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys in roots.yml\n",
    "SRC_ROOT_KEY = 'raw_chronic'\n",
    "TGT_ROOT_KEY = 'catgt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATGT_PATH = \"/Volumes/scratch/neuropixels/bin/CatGT-linux/runit.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_catgt(run_specs, dry_run=dry_run):\n",
    "    subj_id, exp_id, run_id, run_catgt_cfg = run_specs\n",
    "    \n",
    "    catgt_cfg = {\n",
    "        **run_catgt_cfg,\n",
    "        **catgt_base_cfg,\n",
    "    }\n",
    "    \n",
    "    for key in ['g', 't', 'prb']:\n",
    "        assert key in catgt_cfg\n",
    "    \n",
    "    src_dir = paths.get_subject_root(subject, SRC_ROOT_KEY)/exp_id\n",
    "    dest_dir = paths.get_subject_root(subject, TGT_ROOT_KEY)/exp_id\n",
    "    \n",
    "    cmd = get_catGT_command(\n",
    "        catGT_path=CATGT_PATH,\n",
    "        wine_path=None,\n",
    "        dir=str(src_dir),\n",
    "        dest=str(dest_dir),\n",
    "        run=run_id,\n",
    "        ap=ap,\n",
    "        lf=lf,\n",
    "        SY=f\"{catgt_cfg['prb']},{sync_channel},6,500\",\n",
    "        prb_fld=True,\n",
    "        out_prb_fld=True,\n",
    "        **catgt_cfg,\n",
    "    )\n",
    "\n",
    "    start = datetime.now()\n",
    "    print(f\"Running {cmd}\")\n",
    "    if dry_run:\n",
    "        print(\"Dry run: doing nothing\")\n",
    "    else:\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        process = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    end = datetime.now()\n",
    "\n",
    "    print(f\"{end.strftime('%H:%M:%S')}: Finished {subj_id}, {run_id}. Run time = {str(end - start)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_jobs == 1:\n",
    "    for run_specs in all_run_specs:\n",
    "        print(run_specs)\n",
    "        run_catgt(run_specs, dry_run=dry_run)\n",
    "else:\n",
    "    parallel = Parallel(\n",
    "        n_jobs=n_jobs,\n",
    "        backend='multiprocessing',\n",
    "    )(delayed(run_catgt)(run_specs, dry_run=dry_run) for run_specs in all_run_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
