{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecephys_analyses.on_off import get_on_off_df_filename\n",
    "from ecephys_analyses.data.paths import get_datapath\n",
    "import pandas as pd\n",
    "\n",
    "from ecephys_analyses.data.channel_groups import region_depths\n",
    "from ecephys_analyses.data import paths\n",
    "import ecephys.units\n",
    "\n",
    "import itertools \n",
    "\n",
    "from utils import *\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER INPUT BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS\n",
    "\n",
    "data_conditions = [\n",
    "#     (\n",
    "#         'Segundo',\n",
    "#         'sleep-homeostasis-2h_imec0',\n",
    "#         'ks2_5_catgt_Th=12-10_lam=50_8s-batches_postpro_1_metrics_all_isi',\n",
    "#     ), etc\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS USED IN COMPUTE_...\n",
    "\n",
    "region_orig = 'all'\n",
    "\n",
    "selected_groups_orig = ['good', 'mua', 'noise_contam'] # remember that i have either to add noise contam or do selection afterwards \n",
    "\n",
    "selection_intervals_orig = {\n",
    "    'fr': (0.0, float('Inf')),\n",
    "}\n",
    "\n",
    "pool = False\n",
    "assert not pool  # Don't pool\n",
    "\n",
    "state = 'N2'\n",
    "\n",
    "detection_condition = 'on_off_threshold_single_unit_2'\n",
    "\n",
    "root_key = 'sleep-homeostasis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS FOR CURRENT ANALYSIS\n",
    "\n",
    "# Cluster subselection\n",
    "region = 'cortex_base'\n",
    "\n",
    "selected_groups = ['good', 'mua']\n",
    "\n",
    "selection_intervals =  {\n",
    "    'fr': (0.5, 5.0),\n",
    "    'isi_viol_2.0': (0.0, 0.25),\n",
    "#     'isi_viol_1_0': (0.0, 0.25),\n",
    "#     'contam_rate_1_0': (0.0, float('Inf')),\n",
    "#     'contam_rate_2_0': (0.0, float('Inf')),\n",
    "# etc\n",
    "}\n",
    "\n",
    "# Removal of outliers (baseline vs recovery FR)\n",
    "MAD_THRESHOLD = 3 # unit of Median absolute deviation ( 3 (very conservative), 2.5 (moderately conservative) or even 2 (poorly conservative).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END USER INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA AND SUBSET CLUSTERS OF INTEREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, off_dat, cluster_info = load_analysis_data(\n",
    "    data_conditions,\n",
    "    detection_condition,\n",
    "    state,\n",
    "    region_orig,\n",
    "    selected_groups_orig,\n",
    "    selection_intervals_orig,\n",
    "    region,\n",
    "    selected_groups,\n",
    "    selection_intervals,\n",
    "    pool,\n",
    "    root_key='SD',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check some info about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N clusters\n",
    "data.groupby(['dataset', 'condition']).nunique()['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On-Off period durations\n",
    "data.groupby(['dataset', 'condition', 'state']).describe()['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total time spend in state for each condition\n",
    "data.groupby(['dataset', 'condition']).describe()['condition_state_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean outliers (different firing rate for recovery vs baseline)\n",
    "\n",
    "exclude clusters with MAD of difference above threshold for (within state) FR during baseline vs recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_dat = data[\n",
    "    (data['state'] == 'on')\n",
    "    & (data['condition'] != 'interbout')\n",
    "]\n",
    "\n",
    "FR_df = on_dat.groupby(['dataset', 'cluster_id', 'condition', 'condition_state_time']).count()['duration'].reset_index()\n",
    "FR_df = FR_df.rename(columns={'duration': 'n_spikes'})\n",
    "\n",
    "FR_df['condition_FR'] = FR_df['n_spikes'] / FR_df['condition_state_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Firing rate DURING STATE OF INTEREST for baseline vs recovery\n",
    "FR_df.groupby(['dataset', 'condition']).describe()['condition_FR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR_df_wide = pd.pivot_table(\n",
    "    FR_df,\n",
    "    values = 'condition_FR',\n",
    "    index=['dataset','cluster_id'],\n",
    "    columns = 'condition'\n",
    ").reset_index()\n",
    "\n",
    "FR_df_wide['diff'] = FR_df_wide['recovery'] - FR_df_wide['baseline']\n",
    "FR_df_wide['ratio'] = FR_df_wide['recovery'] / FR_df_wide['baseline']\n",
    "FR_df_wide['ratio_inv'] = 1 / FR_df_wide['ratio']\n",
    "\n",
    "FR_df_wide[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe recovery/baseline ratios of FR \n",
    "FR_df_wide.groupby(['dataset']).describe()['ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe baseline/recovery ratios_inv of FR \n",
    "FR_df_wide.groupby(['dataset']).describe()['ratio_inv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = FR_df_wide['diff'].hist(bins=100, by=FR_df_wide['dataset'], bottom=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = FR_df_wide['ratio'].hist(bins=50, by=FR_df_wide['dataset'], bottom=0.01)\n",
    "# set log scale\n",
    "# try:\n",
    "#     for a in axes.ravel(): a.set_xscale('log')\n",
    "# except AttributeError:\n",
    "#     axes.set_xscale('log')\n",
    "\n",
    "# on_duration_df['ratio'].hist(bins=100, by=on_duration_df['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = FR_df_wide['ratio_inv'].hist(bins=50, by=FR_df_wide['dataset'], bottom=0.01)\n",
    "# try:\n",
    "#     for a in axes.ravel(): a.set_xscale('log')\n",
    "# except AttributeError:\n",
    "#     axes.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many NAN ratios (if cluster missing from one of the conditions)\n",
    "\n",
    "FR_df_wide.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN ratios with Inf\n",
    "\n",
    "# Ratio or ratio_inv is NaN if the cluster is missing from one of the conditions (that is if it's rate in this condition is 0)\n",
    "FR_df_wide['ratio'] = FR_df_wide['ratio'].fillna(float('Inf'))\n",
    "FR_df_wide['ratio_inv'] = FR_df_wide['ratio_inv'].fillna(float('Inf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for dataset in data.dataset.unique():\n",
    "    print(dataset, end=': ')\n",
    "    df = FR_df_wide[\n",
    "        (FR_df_wide['dataset'] == dataset)\n",
    "    ]\n",
    "    \n",
    "    exclude_clusters = df[\n",
    "#         ((df['diff'] - df['diff'].median()) > MAD_THRESHOLD * stats.median_abs_deviation(df['diff']))\n",
    "#         | ((df['diff'] - df['diff'].median()) < - MAD_THRESHOLD * stats.median_abs_deviation(df['diff']))\n",
    "        ((df['ratio'] - df['ratio'].median()) > MAD_THRESHOLD * stats.median_abs_deviation(df['ratio']))\n",
    "        | ((df['ratio_inv'] - df['ratio_inv'].median()) > MAD_THRESHOLD * stats.median_abs_deviation(df['ratio_inv']))\n",
    "    ].cluster_id.unique()\n",
    "    print(f'exclude N={len(exclude_clusters)}/{len(df.cluster_id.unique())}: {exclude_clusters}')\n",
    "    \n",
    "    cluster_ids = sorted([c for c in df.cluster_id.unique() if c not in exclude_clusters])\n",
    "    off_dat = off_dat[\n",
    "        (off_dat['dataset'] != dataset)\n",
    "        | off_dat['cluster_id'].isin(cluster_ids)\n",
    "    ].copy()\n",
    "    data = data[\n",
    "        (data['dataset'] != dataset)\n",
    "        | data['cluster_id'].isin(cluster_ids)\n",
    "    ].copy()\n",
    "\n",
    "    # Also FR_df to plot the histograms without outliers\n",
    "    FR_df_wide = FR_df_wide[\n",
    "        (FR_df_wide['dataset'] != dataset)\n",
    "        | FR_df_wide['cluster_id'].isin(cluster_ids)\n",
    "    ]\n",
    "    FR_df = FR_df[\n",
    "        (FR_df['dataset'] != dataset)\n",
    "        | FR_df['cluster_id'].isin(cluster_ids)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = FR_df_wide['diff'].hist(bins=50, by=FR_df_wide['dataset'], bottom=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = FR_df_wide['ratio'].hist(bins=50, by=FR_df_wide['dataset'], bottom=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = FR_df_wide['ratio_inv'].hist(bins=50, by=FR_df_wide['dataset'], bottom=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check again some info about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N clusters\n",
    "off_dat.groupby(['dataset', 'condition']).nunique()['cluster_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe Firing rate DURING STATE OF INTEREST for baseline vs recovery\n",
    "FR_df.groupby(['dataset', 'condition']).describe()['condition_FR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTS\n",
    "\n",
    "\n",
    "# TODO: Split by dataset\n",
    "\n",
    "# DON\"T RUN THIS SECTION IF THERE ARE MULTIPLE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(off_dat.dataset.unique()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_clust = 40\n",
    "\n",
    "np.random.seed(0)\n",
    "cluster_ids = sorted(data.cluster_id.unique())\n",
    "np.random.shuffle(cluster_ids)\n",
    "cluster_select = cluster_ids[0:0+N_clust]\n",
    "# cluster_select = cluster_ids[40:40+N_clust]\n",
    "\n",
    "off_dat = off_dat[off_dat['cluster_id'].isin(cluster_select)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facetted chart order and title\n",
    "off_dat['unit'] = off_dat.apply(\n",
    "    lambda row: f\"cluster_id={row['cluster_id']}, FR={round(row['cumFR'], 2)}Hz\",\n",
    "    axis=1\n",
    ")\n",
    "# Sort by FR\n",
    "off_dat = off_dat.sort_values(by='cumFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENSITY OF OFF PERIODS DURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "duration_density = alt.Chart(\n",
    "    off_dat\n",
    ").transform_density(\n",
    "    'duration',\n",
    "    as_=['duration', 'density'],\n",
    "    groupby=['subject', 'condition', 'unit']\n",
    ").mark_area(\n",
    "    opacity=0.3,\n",
    "#     interpolate='step'\n",
    ").encode(\n",
    "    x=\"duration:Q\",\n",
    "    y='density:Q',\n",
    "    color='condition:N',\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=100,\n",
    ").facet(\n",
    "    facet=alt.Facet(\n",
    "        'unit:N',\n",
    "#         sort=unit_order,\n",
    "    ),\n",
    "    columns=5,\n",
    ").resolve_scale(\n",
    "    x='independent',\n",
    "    y='independent',\n",
    ")\n",
    "\n",
    "duration_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREQUENCY OF OFF PERIODS DURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binwidth = 0.25\n",
    "bins = np.arange(\n",
    "    off_dat.duration.min(),\n",
    "#     off_dat.duration.max() + binwidth,\n",
    "    10 + binwidth,\n",
    "    binwidth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count in each bin\n",
    "\n",
    "binned_durations = off_dat.groupby(\n",
    "    [\n",
    "        'unit',\n",
    "        'condition',\n",
    "         pd.cut(off_dat.duration, bins=bins)\n",
    "    ]\n",
    ").count().loc[:,'state'].reset_index()\n",
    "binned_durations['duration_count'] = binned_durations['state']\n",
    "binned_durations['bin_min'] = binned_durations.apply(lambda row: row['duration'].left, axis=1)\n",
    "binned_durations['bin_max'] = binned_durations.apply(lambda row: row['duration'].right, axis=1)\n",
    "binned_durations['bin_center'] = (binned_durations['bin_min'] + binned_durations['bin_max']) / 2\n",
    "\n",
    "# Normalize by condition duration\n",
    "cond_durations = {\n",
    "    cond: off_dat[off_dat.condition == cond].condition_state_time.unique()[0]\n",
    "    for cond in off_dat.condition.unique()\n",
    "}\n",
    "binned_durations['frequency'] = binned_durations.apply(\n",
    "    lambda row: 60 * row['duration_count'] / cond_durations[row['condition']],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_durations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "duration_frequency = alt.Chart(\n",
    "   binned_durations.drop(columns='duration')\n",
    ").mark_bar(\n",
    "    opacity=0.3,\n",
    ").encode(\n",
    "    x=alt.X('bin_min:Q'),\n",
    "    x2=alt.X2('bin_max:Q'),\n",
    "    y=alt.Y(\n",
    "        'frequency:Q',\n",
    "        axis=alt.Axis(\n",
    "            title=\"Occurrence (per min)\"\n",
    "        ),\n",
    "    ),\n",
    "    color='condition:N',\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=100,\n",
    ").facet(\n",
    "    facet=alt.Facet(\n",
    "        'unit:N',\n",
    "#         sort=unit_order,\n",
    "    ),\n",
    "    columns=5,\n",
    ").resolve_scale(\n",
    "    x='independent',\n",
    "    y='independent',\n",
    ")\n",
    "\n",
    "duration_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = ['mean', 'median', 'skew']\n",
    "\n",
    "stats_df = off_dat.groupby(\n",
    "    ['dataset', 'condition', 'cluster_id']\n",
    ").agg({\n",
    "    'duration': funcs,\n",
    "})['duration'].reset_index()\n",
    "\n",
    "stats_df[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots with mean/median/skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = [\n",
    "    alt.Chart(\n",
    "        stats_df[stats_df['dataset'] == dataset]\n",
    "    ).transform_fold(\n",
    "        fold=funcs,\n",
    "    ).mark_boxplot(\n",
    "        color='black',\n",
    "        extent=0,\n",
    "    ).encode(\n",
    "        x=alt.X(\n",
    "            'condition:N',\n",
    "        ),\n",
    "        y=alt.Y(\n",
    "            'value:Q',\n",
    "            axis=alt.Axis(\n",
    "                title='Value',\n",
    "            ),\n",
    "            scale=alt.Scale(\n",
    "                zero=False,\n",
    "            ),\n",
    "        ),\n",
    "        column=alt.Column(\n",
    "            'key:N',\n",
    "            header=alt.Header(\n",
    "                title=\"Measure\"\n",
    "            ),\n",
    "        ),\n",
    "#         row=alt.Row('dataset'),\n",
    "        color=alt.Color('condition:N')\n",
    "    ).properties(\n",
    "        title=f\"{dataset}, N={len(stats_df[stats_df['dataset'] == dataset].cluster_id.unique())}\",\n",
    "        width=50,\n",
    "        height=300\n",
    "    ).resolve_scale(\n",
    "        y='independent'\n",
    "    )\n",
    "    for dataset in stats_df.dataset.unique()\n",
    "]\n",
    "\n",
    "concat = alt.hconcat()\n",
    "for chart in charts:\n",
    "    concat = alt.hconcat(concat, chart, spacing=70)\n",
    "\n",
    "concat.configure_title(\n",
    "    fontSize=15,\n",
    ").configure_axis(\n",
    "    labelFontSize = 12,\n",
    "    titleFontSize = 14\n",
    ").configure_header(\n",
    "    labelFontSize = 14,\n",
    "    titleFontSize = 14\n",
    ").configure_legend(\n",
    "    labelFontSize = 14,\n",
    "    titleFontSize = 14\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots with median only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = [\n",
    "    alt.Chart(\n",
    "        stats_df[stats_df['dataset'] == dataset]\n",
    "    ).transform_fold(\n",
    "        fold=funcs,\n",
    "    ).mark_boxplot(\n",
    "        color='black',\n",
    "        extent=0,\n",
    "    ).encode(\n",
    "        x=alt.X(\n",
    "            'condition:N',\n",
    "        ),\n",
    "        y=alt.Y(\n",
    "            'median:Q',\n",
    "            axis=alt.Axis(\n",
    "                title=\"Units' median off period duration\",\n",
    "            ),\n",
    "            scale=alt.Scale(\n",
    "                zero=False,\n",
    "            ),\n",
    "        ),\n",
    "#         row=alt.Row('dataset'),\n",
    "        color=alt.Color('condition:N')\n",
    "    ).properties(\n",
    "        title=f\"{dataset}, N={len(stats_df[stats_df['dataset'] == dataset].cluster_id.unique())}\",\n",
    "        width=50,\n",
    "        height=300\n",
    "    )\n",
    "    for dataset in stats_df.dataset.unique()\n",
    "]\n",
    "\n",
    "concat = alt.hconcat()\n",
    "for chart in charts:\n",
    "    concat = alt.hconcat(concat, chart, spacing=70)\n",
    "\n",
    "concat.configure_title(\n",
    "    fontSize=15,\n",
    ").configure_axis(\n",
    "    labelFontSize = 12,\n",
    "    titleFontSize = 14\n",
    ").configure_header(\n",
    "    labelFontSize = 14,\n",
    "    titleFontSize = 14\n",
    ").configure_legend(\n",
    "    labelFontSize = 14,\n",
    "    titleFontSize = 14\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "scipy.stats.ttest_rel(\n",
    "    stats_df[stats_df['condition'] == 'baseline'].sort_values(by='cluster_id')['skew'],\n",
    "    stats_df[stats_df['condition'] == 'recovery'].sort_values(by='cluster_id')['skew'],\n",
    "    axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_rel(\n",
    "    stats_df[stats_df['condition'] == 'baseline'].sort_values(by='cluster_id')['mean'],\n",
    "    stats_df[stats_df['condition'] == 'recovery'].sort_values(by='cluster_id')['mean'],\n",
    "    axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_rel(\n",
    "    stats_df[stats_df['condition'] == 'baseline'].sort_values(by='cluster_id')['median'],\n",
    "    stats_df[stats_df['condition'] == 'recovery'].sort_values(by='cluster_id')['median'],\n",
    "    axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
